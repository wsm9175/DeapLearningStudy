{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FP.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN1nZLJy5Mc+LremhO1Q372",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wsm9175/DeepLearningStudy/blob/main/FP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Activation Function 실습"
      ],
      "metadata": {
        "id": "tihqZYQpJ-KV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1-3-1 Activation Layers"
      ],
      "metadata": {
        "id": "Z9DPKd33KEhL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "#max - Returns the max of x and y (i.e. x > y ? x : y)\n",
        "#Computes exponential of x element-wise.\n",
        "from tensorflow.math import exp, maximum  \n",
        "from tensorflow.keras.layers import Activation\n",
        "\n",
        "# input setting  tf.random.normal - Outputs random values from a normal distribution\n",
        "x = tf.random.normal(shape=(1, 5))\n",
        "\n",
        "# activation function\n",
        "sigmoid = Activation('sigmoid')\n",
        "tanh = Activation('tanh')\n",
        "relu = Activation('relu')\n",
        "\n",
        "# forward propagation(tensorflow)\n",
        "y_sigmoid_tf = sigmoid(x)\n",
        "y_tanh_tf = tanh(x)\n",
        "y_relu_tf = relu(x)\n",
        "\n",
        "# forward propagation(manual)\n",
        "y_sigmoid_man = 1 / (1+exp(-x))\n",
        "y_tanh_man = (exp(x) - exp(-x)) / (exp(x) + exp(-x))\n",
        "y_relu_man = maximum(x, 0)\n",
        "\n",
        "print(f\"x:{x.shape}\\n{x.numpy()}\") # 1, 5\n",
        "print(f\"sigmoid(Tensorflow): {y_sigmoid_tf.shape}\\n{y_sigmoid_tf.numpy()}\") # 1, 5\n",
        "print(f\"sigmoid(manual): {y_sigmoid_man.shape}\\n{y_sigmoid_man.numpy()}\", end=\"\\n\\n\") # 1, 5\n",
        "\n",
        "print(f\"Tanh(Tensorflow): {y_tanh_tf.shape}\\n{y_tanh_tf.numpy()}\")\n",
        "print(f\"Tanh(manual): {y_tanh_man.shape}\\n{y_tanh_man.numpy()}\", end=\"\\n\\n\")\n",
        "\n",
        "print(f\"relu(Tensorflow): {y_relu_tf.shape}\\n{y_relu_tf.numpy()}\")\n",
        "print(f\"relu(manual): {y_relu_man.shape}\\n{y_relu_man.numpy()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vW5DnwYBKB9Y",
        "outputId": "e74ac1f6-f579-4e08-ae48-44b9873b07bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x:(1, 5)\n",
            "[[-1.0090201  1.1141306  0.6600343 -0.7265979 -0.7278725]]\n",
            "sigmoid(Tensorflow): (1, 5)\n",
            "[[0.2671717  0.7528984  0.6592681  0.32594174 0.32566178]]\n",
            "sigmoid(manual): (1, 5)\n",
            "[[0.26717168 0.7528984  0.65926814 0.32594174 0.32566175]]\n",
            "\n",
            "Tanh(Tensorflow): (1, 5)\n",
            "[[-0.7653565   0.80551773  0.57838625 -0.6209796  -0.62176204]]\n",
            "Tanh(manual): (1, 5)\n",
            "[[-0.76535636  0.8055176   0.5783862  -0.6209796  -0.62176204]]\n",
            "\n",
            "relu(Tensorflow): (1, 5)\n",
            "[[0.        1.1141306 0.6600343 0.        0.       ]]\n",
            "relu(manual): (1, 5)\n",
            "[[0.        1.1141306 0.6600343 0.        0.       ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code. 1-3-2: Activation in Dense Layer"
      ],
      "metadata": {
        "id": "yHAuJjlYmgpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.math import maximum\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "x = tf.random.normal(shape=(1, 5)) # input setting\n",
        "\n",
        "# artificial neurons\n",
        "dense_sigmoid = Dense(units=1, activation='sigmoid') # unit - Artificial neuron\n",
        "dense_tanh = Dense(units=1, activation='tanh')\n",
        "dense_relu = Dense(units=1, activation='relu')\n",
        "\n",
        "# forward propagaion\n",
        "y_sigmoid = dense_sigmoid(x)\n",
        "y_tanh = dense_tanh(x)\n",
        "y_relu = dense_relu(x)\n",
        "\n",
        "print(f\"AN with sigmoid: {y_sigmoid.shape}\\n{y_sigmoid.numpy()}\") \n",
        "print(f\"AN with tanh: {y_tanh.shape}\\n{y_tanh.numpy()}\")\n",
        "print(f\"An with relu: {y_relu.shape}\\n{y_relu.numpy()}\")\n",
        "\n",
        "print('\\n===================================\\n')\n",
        "\n",
        "# forward propagaion(manual)\n",
        "# Dense_sigmoid로 부터 Weight, Bias를 가져옴\n",
        "W, B = dense_sigmoid.get_weights()\n",
        "print(f'W{W} \\nB{B} \\nx{x}') # W - (5, 1), B - (1, ), x - (1, 5)\n",
        "# Weight, Bias를 바탕으로 input matrix와 행렬 곱 수행 및 Bias를 더해줌\n",
        "z = tf.linalg.matmul(x, W) + B # matmul: 행렬 곱  \n",
        "# Activation Function - Sigmoid\n",
        "a = 1 / (1+exp(-z))\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHafYn5Bj0N6",
        "outputId": "0ead62b3-8d2d-4e01-9c55-1946041682ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AN with sigmoid: (1, 1)\n",
            "[[0.609048]]\n",
            "AN with tanh: (1, 1)\n",
            "[[0.73754156]]\n",
            "An with relu: (1, 1)\n",
            "[[1.4351355]]\n",
            "\n",
            "===================================\n",
            "\n",
            "W[[ 0.14740849]\n",
            " [ 0.7600348 ]\n",
            " [-0.9701698 ]\n",
            " [-0.09509254]\n",
            " [-0.45259237]] \n",
            "B[0.] \n",
            "x[[-2.6182420e+00  5.5536658e-01 -3.8652912e-01 -3.3534023e-01\n",
            "  -6.1476888e-04]]\n",
            "tf.Tensor([[0.609048]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.math import exp, maximum\n",
        "\n",
        "activation = 'sigmoid'\n",
        "\n",
        "x = tf.random.uniform(shape=(1, 10))\n",
        "\n",
        "dense = Dense(units=1, activation=activation) # affine + activation\n",
        "              \n",
        "y_tf = dense(x)\n",
        "print(y_tf)\n",
        "\n",
        "W, B = dense.get_weights()\n",
        "\n",
        "# calculate activation value manually\n",
        "y_man = tf.linalg.matmul(x, W) + B\n",
        "y_man = 1/(1+exp(-y_man))\n",
        "print(y_man)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXkE5XIhncxA",
        "outputId": "18fc0341-02d5-4eee-a35c-c80a719e8088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[0.45120633]], shape=(1, 1), dtype=float32)\n",
            "tf.Tensor([[0.45120633]], shape=(1, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "shapes of Dense Layers"
      ],
      "metadata": {
        "id": "wGFARMeCwS3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "N, n_feature = 8, 10\n",
        "x = tf.random.normal(shape=(N, n_feature)) # generate minibatch\n",
        "print(x.shape)\n",
        "\n",
        "dense = Dense(units=1, activation='relu')\n",
        "y = dense(x)\n",
        "\n",
        "# Wight, Bias는 input 행의 개수에 영향을 받지 않는다.\n",
        "W, B = dense.get_weights()\n",
        "print(\"Shape of x: \", x.shape) # (8, 10)\n",
        "print(\"Shape of W: \", W.shape) # (Input_feature, the number of neurons)) -> (10,1)\n",
        "print(\"Shape of B: \", B.shape) # (the number of neurons) -> (10, )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWe0J3bJvve1",
        "outputId": "11b708ba-9d75-49cf-a6c5-07765c7449cc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 10)\n",
            "Shape of x:  (8, 10)\n",
            "Shape of W:  (10, 1)\n",
            "Shape of B:  (1,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code. 1-5-2 Output Calculation"
      ],
      "metadata": {
        "id": "ByOX7NfkScDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "N, n_feature = 8, 10\n",
        "x = tf.random.normal(shape=(N, n_feature)) # generate minibatch\n",
        "\n",
        "dense = Dense(units=1, activation = 'sigmoid') # imp, an AN\n",
        "y_tf = dense(x) # foward propagation Tensor\n",
        "\n",
        "W, B = dense.get_weights()\n",
        "\n",
        "# manual\n",
        "y_man = tf.linalg.matmul(x, W) + B\n",
        "y_man = 1/(1+tf.math.exp(-y_man))\n",
        "\n",
        "#print results\n",
        "print(\"Output(Tensorflow): \\n\", y_tf.numpy())\n",
        "print(\"Output(Manual): \\n\", y_man.numpy())\n",
        "print(tf.math.equal(y_tf, y_man))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNm7Q1udwpjt",
        "outputId": "0730203b-a0c4-46a3-c2b7-5d3d9af71468"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output(Tensorflow): \n",
            " [[0.16918442]\n",
            " [0.8744273 ]\n",
            " [0.8723631 ]\n",
            " [0.3687498 ]\n",
            " [0.4484246 ]\n",
            " [0.7458326 ]\n",
            " [0.48593822]\n",
            " [0.8058391 ]]\n",
            "Output(Manual): \n",
            " [[0.1691844 ]\n",
            " [0.87442726]\n",
            " [0.87236303]\n",
            " [0.3687498 ]\n",
            " [0.44842464]\n",
            " [0.7458326 ]\n",
            " [0.48593825]\n",
            " [0.8058391 ]]\n",
            "tf.Tensor(\n",
            "[[False]\n",
            " [False]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]\n",
            " [False]\n",
            " [ True]], shape=(8, 1), dtype=bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code.2-1-1: Shapes of Dense Layers"
      ],
      "metadata": {
        "id": "cn49RjQ5SlDj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "N, n_feature = 8, 10 # N - batchsize\n",
        "X = tf.random.normal(shape=(N, n_feature)) # (1, 10) 행렬\n",
        "\n",
        "n_neuron = 3\n",
        "dense = Dense(units=n_neuron, activation='sigmoid')\n",
        "Y = dense(X)\n",
        "\n",
        "W, B = dense.get_weights()\n",
        "\n",
        "print('==== Input/Weight/bias ====')\n",
        "print('X: ', X.shape) # 8, 10\n",
        "print('W: ', W.shape) # 10, 3\n",
        "print('B: ', B.shape) # 10, \n",
        "print('Y: ', Y.shape) # 8, 3\n",
        "\n",
        "print(X.numpy())\n",
        "print(W)\n",
        "print(Y.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WJBiEIe50_e",
        "outputId": "9e9d6327-5464-48a3-d62a-7fa252c203cc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== Input/Weight/bias ====\n",
            "X:  (8, 10)\n",
            "W:  (10, 3)\n",
            "B:  (3,)\n",
            "Y:  (8, 3)\n",
            "[[-0.38205552 -0.45030057 -0.2573847   0.01237032  1.3987805   0.09815046\n",
            "   0.36869457 -1.3067293  -0.41829124 -0.4291312 ]\n",
            " [-0.7919713   0.25941178 -0.40508628 -0.2745618  -0.5430084   0.5814999\n",
            "   0.53034085  1.9772941   0.93749815 -1.4025333 ]\n",
            " [-1.2837842  -1.6288426   0.9276947  -1.7925206   0.9474805   0.3818545\n",
            "   3.0268989   0.0290732   0.812758    0.5514525 ]\n",
            " [ 1.7728289   0.22777899 -0.3783955   0.28738135  0.26365623 -1.0954878\n",
            "   0.90043986  0.6281416  -0.4667178  -0.27795398]\n",
            " [-0.04531534 -0.8555465  -0.81288534 -1.2335558  -0.37511435  0.8695283\n",
            "   1.3844451   1.1177456   0.9289346   0.63200563]\n",
            " [-0.7801288  -0.26284257  0.4599856  -1.2211821  -0.46178487 -1.3548064\n",
            "   0.7739596   0.08491572 -0.59735787 -0.5004451 ]\n",
            " [ 0.65903586  0.96519375 -0.9963751  -0.26402247 -1.382591   -1.6495672\n",
            "   0.03229915  0.9127999   1.1559516   0.06113651]\n",
            " [-0.505244   -0.64534897  0.35026267  0.5792075  -0.54676163  1.5896624\n",
            "  -0.09010227 -0.13134211 -0.71731305  1.6366384 ]]\n",
            "[[-0.03911322  0.12612265 -0.34760895]\n",
            " [ 0.13070065 -0.29071754  0.32035172]\n",
            " [ 0.06608957 -0.6136889  -0.33102724]\n",
            " [-0.6275886   0.52451384  0.31772387]\n",
            " [ 0.2348454   0.5248929  -0.1256147 ]\n",
            " [-0.44091332  0.6255413  -0.6246221 ]\n",
            " [-0.17093259  0.22731042  0.21901977]\n",
            " [-0.5482945   0.26347488 -0.1670177 ]\n",
            " [-0.10278517 -0.34799948 -0.44878346]\n",
            " [ 0.15870667 -0.65582806  0.47037053]]\n",
            "[[0.6994909  0.7701739  0.53134346]\n",
            " [0.15879294 0.7761043  0.23428342]\n",
            " [0.6337617  0.39879248 0.3193047 ]\n",
            " [0.45153654 0.67003244 0.6213893 ]\n",
            " [0.33053553 0.57769555 0.2931261 ]\n",
            " [0.74743634 0.2141178  0.6767727 ]\n",
            " [0.49693173 0.15754527 0.7098572 ]\n",
            " [0.30717522 0.5103321  0.55148196]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.math import exp \n",
        "from tensorflow.linalg import matmul\n",
        "\n",
        "N, n_feature = 4,10\n",
        "X = tf.random.normal(shape=(N, n_feature))\n",
        "\n",
        "n_neuron = 3\n",
        "dense = Dense(units=n_neuron, activation='sigmoid')\n",
        "Y_tf = dense(X)\n",
        "\n",
        "W, B = dense.get_weights()\n",
        "print(\"Y(Tensorflow): \\n\", Y_tf.numpy())\n",
        "\n",
        "# manual\n",
        "z = matmul(X, W) + B # Affine \n",
        "y_man_matmul = 1/(1+exp(-z)) # Activation\n",
        "print(\"Y(with matrix multiplication: \\n\", y_man_matmul.numpy())\n",
        "\n",
        "# calculate with matrix multiplication\n",
        "y_man_vec = np.zeros(shape=(N, n_neuron)) # neuron에서의 연산 결과: (N, n_neuron)\n",
        "\n",
        "for x_idx in range(N):\n",
        "  x = X[x_idx] # 하나의 input data씩 빼옴\n",
        "\n",
        "  for nu_idx in range(n_neuron):\n",
        "    w, b = W[:, nu_idx], B[nu_idx] # W - (10, 3), B - (10, ), \n",
        "\n",
        "    z = tf.reduce_sum(x * w) + b\n",
        "    a = 1/(1+np.exp(-z))\n",
        "    y_man_vec[x_idx, nu_idx] = a\n",
        "\n",
        "  print(y_man_vec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQ6TYSJF84QT",
        "outputId": "b1f695c4-8bd4-4865-da61-5d52e8864f34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Y(Tensorflow): \n",
            " [[0.22057503 0.76621556 0.4507358 ]\n",
            " [0.5104988  0.2198754  0.29087013]\n",
            " [0.8218975  0.5118218  0.19009319]\n",
            " [0.87203234 0.86666894 0.02511972]]\n",
            "Y(with matrix multiplication: \n",
            " [[0.220575   0.7662156  0.4507358 ]\n",
            " [0.51049876 0.21987538 0.29087016]\n",
            " [0.8218975  0.51182187 0.19009316]\n",
            " [0.8720324  0.866669   0.02511972]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2-2 Cascaded dense Layers"
      ],
      "metadata": {
        "id": "FvqKih8nfp-A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2-2-1: Shapes of Cascaded Dense layers"
      ],
      "metadata": {
        "id": "rEU2ZItTf1O3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "N, n_feature = 4, 10\n",
        "X = tf.random.normal(shape=(N, n_feature))\n",
        "\n",
        "n_neurons = [3, 5]\n",
        "dense1 = Dense(units=n_neurons[0], activation='sigmoid')\n",
        "dense2 = Dense(units=n_neurons[1], activation='sigmoid')\n",
        "\n",
        "# forward propagation\n",
        "A1 = dense1(X)\n",
        "Y = dense2(A1)\n",
        "\n",
        "W1, B1 = dense1.get_weights() \n",
        "W2, B2 = dense2.get_weights()\n",
        "\n",
        "print(f\"W1: {W1.shape}\\n\")\n",
        "print(f\"B1: {B1.shape}\\n\")\n",
        "print(f\"A1: {A1.shape}\\n\")\n",
        "\n",
        "print(f\"W2: {W2.shape}\\n\")\n",
        "print(f\"B2: {B2.shape}\\n\")\n",
        "print(f\"Y: {Y.shape}\")"
      ],
      "metadata": {
        "id": "cA0jHO5B-7YW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "099ed200-4842-408e-f48c-4ace7e2c6fd8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W1: (10, 3)\n",
            "\n",
            "B1: (3,)\n",
            "\n",
            "A1: (4, 3)\n",
            "\n",
            "W2: (3, 5)\n",
            "\n",
            "B2: (5,)\n",
            "\n",
            "Y: (4, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code.2-2-2: Dense Layers with python List"
      ],
      "metadata": {
        "id": "a0fnTK3BkUko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "N, n_feature = 4, 10\n",
        "X = tf.random.normal(shape=(N, n_feature))\n",
        "\n",
        "n_neurons = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "\n",
        "dense_layers = list()\n",
        "\n",
        "for n_neuron in n_neurons:\n",
        "  dense = Dense(units = n_neuron, activation='relu')\n",
        "  dense_layers.append(dense)\n",
        "\n",
        "for dense_idx, dense in enumerate(dense_layers):\n",
        "  X = dense(X)\n",
        "  print(\"After dense layer \", dense_idx)\n",
        "  print(X.shape, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hsCwi7JivfT",
        "outputId": "e5ea3740-259e-4eea-c8ca-c60c52151c6b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After dense layer  0\n",
            "(4, 10) \n",
            "\n",
            "After dense layer  1\n",
            "(4, 20) \n",
            "\n",
            "After dense layer  2\n",
            "(4, 30) \n",
            "\n",
            "After dense layer  3\n",
            "(4, 40) \n",
            "\n",
            "After dense layer  4\n",
            "(4, 50) \n",
            "\n",
            "After dense layer  5\n",
            "(4, 60) \n",
            "\n",
            "After dense layer  6\n",
            "(4, 70) \n",
            "\n",
            "After dense layer  7\n",
            "(4, 80) \n",
            "\n",
            "After dense layer  8\n",
            "(4, 90) \n",
            "\n",
            "After dense layer  9\n",
            "(4, 100) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.math import exp\n",
        "from tensorflow.linalg import matmul\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "N, n_feature = 4, 10\n",
        "X = tf.random.normal(shape=(N, n_feature))\n",
        "X_cp = tf.identity(X)\n",
        "\n",
        "n_neurons = [10, 20, 30]\n",
        "\n",
        "dense_layers = list()\n",
        "for n_neuron in n_neurons:\n",
        "  dense = Dense(units = n_neuron, activation=\"sigmoid\")\n",
        "  dense_layers.append(dense)\n",
        "\n",
        "# forward propagation(Tensorflow)\n",
        "W, B = list(), list()\n",
        "for dense_idx, dense in enumerate(dense_layers):\n",
        "  X = dense(X)\n",
        "  w, b = dense.get_weights()\n",
        "  print(w.shape)\n",
        "  W.append(w)\n",
        "  B.append(b)\n",
        "\n",
        "print(\"Y(Tensor) \", X.numpy())\n",
        "# forward propagation(Manual)\n",
        "for layer_idx in range(len(n_neurons)):\n",
        "  w, b = W[layer_idx], B[layer_idx]\n",
        "  print(w.shape)\n",
        "  X_cp = matmul(X_cp, w) + b\n",
        "  X_cp = 1/(1+exp(-X_cp)) # activation sigmoid\n",
        "\n",
        "# print(\"Y(matmul): \", X_cp.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyjmQrI6nT9f",
        "outputId": "735e42dd-b450-4943-e889-77db10262e35"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 10)\n",
            "(10, 20)\n",
            "(20, 30)\n",
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2-3: Model Implementation"
      ],
      "metadata": {
        "id": "JHLz8kiBxa3B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code.2-3-1: Model Implementation with Sequential Method"
      ],
      "metadata": {
        "id": "risr-OLJxdv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "n_neurons = [3, 4, 5, 6]\n",
        "\n",
        "# list 활용\n",
        "model = list()\n",
        "for n_neuron in n_neurons:\n",
        "  model.append(Dense(units = n_neuron, activation='sigmoid'))\n",
        "\n",
        "#Sequential 활용\n",
        "model = Sequential()\n",
        "for n_neuron in n_neurons:\n",
        "  model.add(Dense(units=n_neuron, activation='sigmoid'))\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(units=10, activation='sigmoid'))\n",
        "model.add(Dense(units=20, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "45nHcuw9xiT5"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "class TestModel(Model):\n",
        "  def __init__(self):\n",
        "    super(TestModel, self).__init__()\n",
        "\n",
        "    self.dense1 = Dense(units=10, activation='sigmoid')\n",
        "    self.dense2 = Dense(units=20, activation='sigmoid')\n",
        "  \n",
        "model = TestModel()\n",
        "print(model.dense1)\n",
        "print(model.dense2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MrCn0VVvA88",
        "outputId": "9b974b2e-b936-4b30-b4f9-700d9d300c51"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<keras.layers.core.dense.Dense object at 0x7fa4d8642210>\n",
            "<keras.layers.core.dense.Dense object at 0x7fa4d8612ad0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "X = tf.random.normal(shape=(4, 10))\n",
        "\n",
        "#Sequential method\n",
        "model = Sequential()\n",
        "model.add(Dense(units=10, activation='sigmoid'))\n",
        "model.add(Dense(units=20, activation='sigmoid'))\n",
        "\n",
        "Y = model(X)\n",
        "\n",
        "# Model-subclassing\n",
        "class TestModel(Model):\n",
        "  def __init__(self):\n",
        "    super(TestModel, self).__init__()\n",
        "\n",
        "    self.dense1 = Dense(units=10, activation='sigmoid')\n",
        "    self.dense2 = Dense(units=20, activation='sigmoid')\n",
        "\n",
        "  def __call__(self, x):\n",
        "    x = self.dense1(x)\n",
        "    x = self.dense2(x)\n",
        "    W, B = dense2.get_weights()\n",
        "    print(\"W1, B1: \", W, B)\n",
        "    return x\n",
        "\n",
        "model = TestModel()\n",
        "Y = model(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAzxekojy8pq",
        "outputId": "c0b14058-c983-4614-90a0-8db240a84ee8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W1, B1:  [array([[ 0.24165428, -0.3595832 ,  0.2361126 ,  0.5297321 , -0.48347393,\n",
            "         0.21606952, -0.07336351,  0.14820504,  0.41083413, -0.00087374],\n",
            "       [ 0.31512374,  0.07172662,  0.01387113, -0.4433536 , -0.3454167 ,\n",
            "        -0.3809709 , -0.40791458,  0.3373593 , -0.36700147, -0.00291121],\n",
            "       [ 0.2638511 , -0.363146  , -0.02388936, -0.3204531 , -0.5301211 ,\n",
            "        -0.47891825, -0.23174298,  0.22747016,  0.413355  , -0.00759327],\n",
            "       [ 0.47039783,  0.2660706 ,  0.46870768,  0.336159  , -0.28244647,\n",
            "         0.4942317 , -0.47054043, -0.18768403,  0.36063105, -0.2108579 ],\n",
            "       [ 0.1654346 , -0.37503284,  0.3085791 ,  0.16584462, -0.31636795,\n",
            "         0.49002278, -0.31850097,  0.2920701 , -0.52467513,  0.01276153],\n",
            "       [ 0.0087052 , -0.11159855, -0.4937092 , -0.2374559 ,  0.49185085,\n",
            "        -0.3074802 , -0.4504702 ,  0.52938056,  0.3717714 , -0.19589445],\n",
            "       [ 0.4556321 ,  0.20078778,  0.02391326,  0.34223312, -0.13242239,\n",
            "        -0.21748507, -0.4497127 , -0.16749081, -0.02097821,  0.06197512],\n",
            "       [ 0.2895614 , -0.02601361,  0.21339273, -0.4441806 ,  0.50361943,\n",
            "        -0.17271754, -0.02494162, -0.51092595, -0.05389649,  0.31627172],\n",
            "       [-0.29619902,  0.30088747, -0.17593628, -0.2548222 ,  0.11566359,\n",
            "        -0.07918444, -0.2770886 , -0.02041298,  0.30646503,  0.15892023],\n",
            "       [-0.46156633, -0.12827402, -0.37076133, -0.30124438,  0.28029847,\n",
            "        -0.16446522, -0.08530205,  0.13696969,  0.07604617,  0.06433082]],\n",
            "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([[-0.11155263,  0.32519776,  0.22253066, -0.21669915,  0.3541    ,\n",
            "        -0.2458313 ,  0.0039469 , -0.2622593 ,  0.31020558, -0.44569206,\n",
            "         0.1548701 ,  0.06747651,  0.19355768,  0.390095  , -0.14776972,\n",
            "        -0.2506106 ,  0.03629589, -0.05980253,  0.30497545,  0.05316049],\n",
            "       [-0.21944131,  0.01462808, -0.29276794, -0.13363287,  0.34236634,\n",
            "         0.1612134 , -0.24976955,  0.18039995, -0.23887195,  0.13142723,\n",
            "         0.3382268 ,  0.24532336, -0.07768434, -0.34077978, -0.41481236,\n",
            "        -0.13192761,  0.02131179,  0.43384057,  0.11021435,  0.2371003 ],\n",
            "       [ 0.31812388,  0.25483155,  0.0336982 ,  0.14151514,  0.3621608 ,\n",
            "        -0.4389049 , -0.14057311,  0.38783276,  0.18360186, -0.16252765,\n",
            "        -0.319528  ,  0.18602055, -0.2640657 ,  0.4378904 ,  0.05283731,\n",
            "         0.1285981 , -0.40998465,  0.27606243,  0.42920327, -0.31280643],\n",
            "       [ 0.22578394, -0.2603392 ,  0.27487165, -0.08349302,  0.44683987,\n",
            "         0.12871236, -0.10947463,  0.33618718, -0.08264396, -0.24824004,\n",
            "         0.42559302, -0.13603243, -0.09659049,  0.10175145, -0.25171897,\n",
            "        -0.11835906, -0.20054753, -0.1301682 , -0.30411017, -0.10398424],\n",
            "       [-0.03657502,  0.14467257, -0.17677027,  0.34786284, -0.08547026,\n",
            "         0.09068471,  0.03249165,  0.23477781,  0.37044865, -0.07022482,\n",
            "         0.0826301 ,  0.43633068,  0.4432798 , -0.3060956 , -0.42941666,\n",
            "         0.21555167, -0.34838867,  0.00768545, -0.4457476 , -0.04867089],\n",
            "       [ 0.3463093 , -0.2092551 , -0.15662962,  0.36535245, -0.09095445,\n",
            "         0.4427563 , -0.24218869,  0.15508252, -0.04963508,  0.43077654,\n",
            "        -0.40836278, -0.25149834, -0.22723414,  0.06105721, -0.05356076,\n",
            "        -0.2907088 ,  0.3114217 , -0.12459785,  0.28392124,  0.02878806],\n",
            "       [ 0.01360437, -0.26524273,  0.20983803, -0.03117025, -0.00722548,\n",
            "        -0.28975794,  0.365995  , -0.16404033,  0.35941404, -0.302256  ,\n",
            "         0.40440202, -0.28329623, -0.4213578 , -0.29453662, -0.3662029 ,\n",
            "        -0.29764885,  0.17526793,  0.00190666, -0.35731363, -0.33490467],\n",
            "       [ 0.34984195,  0.2922672 , -0.4226277 ,  0.1854521 , -0.15796435,\n",
            "        -0.0402959 , -0.24293593, -0.02912989,  0.23434126,  0.41529614,\n",
            "         0.40687358, -0.2891149 ,  0.21640486,  0.23389572, -0.13751727,\n",
            "        -0.01940569, -0.30308968,  0.1528269 ,  0.36366314,  0.3903672 ],\n",
            "       [-0.01246914, -0.2988181 , -0.30819526, -0.34707892, -0.38949746,\n",
            "        -0.20690712, -0.23454525, -0.43994632,  0.03115502, -0.33328155,\n",
            "        -0.0557358 , -0.04492155,  0.11926442, -0.38869256, -0.01539651,\n",
            "        -0.2722811 ,  0.44585115,  0.14498365,  0.4444015 ,  0.0043155 ],\n",
            "       [ 0.2731462 ,  0.04647154, -0.03434509, -0.1676394 ,  0.34961742,\n",
            "        -0.09884486, -0.102741  ,  0.06450838,  0.3302933 ,  0.40662318,\n",
            "        -0.10765326, -0.28514504,  0.33919233, -0.3163312 , -0.11761153,\n",
            "         0.3526178 ,  0.10446274,  0.32709414, -0.31261438, -0.17368862]],\n",
            "      dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0.], dtype=float32)] [array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0.], dtype=float32), array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]\n",
            "W1, B1:  [[-0.21909928 -0.35112017  0.18823665 -0.15421712 -0.30464083]\n",
            " [ 0.85231787  0.4672671   0.46852773  0.72281796  0.49058336]\n",
            " [ 0.79491097  0.2256338  -0.71986085 -0.22969377 -0.3828005 ]] [0. 0. 0. 0. 0.]\n",
            "tf.Tensor(\n",
            "[[0.49441835 0.6435133  0.39970273 0.63232917 0.35426265 0.44432974\n",
            "  0.627727   0.4039751  0.6143916  0.56685144 0.2887678  0.4641956\n",
            "  0.32663873 0.6014451  0.42399654 0.27599138 0.45574498 0.48787457\n",
            "  0.3906061  0.42228955]\n",
            " [0.48357123 0.64375544 0.4597643  0.60371464 0.2955611  0.41850263\n",
            "  0.6122137  0.40706003 0.6183715  0.5576878  0.36288768 0.4834289\n",
            "  0.3561647  0.50976586 0.47337234 0.2643805  0.43955424 0.49650615\n",
            "  0.36246508 0.40371937]\n",
            " [0.5252664  0.66891307 0.5098464  0.6188533  0.2985971  0.456597\n",
            "  0.6094877  0.34671772 0.59659666 0.5693065  0.33629787 0.43239048\n",
            "  0.31547475 0.53291774 0.42396116 0.27323967 0.48507187 0.4842561\n",
            "  0.3575247  0.45766547]\n",
            " [0.45975792 0.656356   0.5232774  0.5672567  0.35203236 0.38742828\n",
            "  0.60837513 0.4009114  0.5449441  0.6217371  0.29096234 0.4969389\n",
            "  0.3680547  0.5427363  0.505886   0.31099367 0.488721   0.44419223\n",
            "  0.39836103 0.44257605]], shape=(4, 20), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iHsy-Z8Szhe1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}